{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAMM Clustering - Whole Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Notebook to use PAMM clustering algorithm (orignal [paper](https://pubs.acs.org/doi/abs/10.1021/acs.jctc.7b00993)) with the GMPLabTools implementation.\n",
    "\n",
    "The keyword **WHOLE** dataset refers to the tratments of the dataset towards the kernel density estimation (KDE), which are \"summed\" togheter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gmplabtools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e11b78bacf07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhierarchy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdendrogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgmplabtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgmplabtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpamm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPammGMM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgmplabtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpamm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPamm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gmplabtools'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "from gmplabtools.analysis import DataSampler\n",
    "from gmplabtools.pamm import PammGMM\n",
    "from gmplabtools.pamm import Pamm\n",
    "from gmplabtools.analysis import calculate_adjacency, adjancency_dendrogram\n",
    "from gmplabtools.analysis import ClusterRates\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_colors(clust,mode='tab20'):\n",
    "    if np.min(clust) == -1:\n",
    "        N = np.unique(clust).shape[0] - 1\n",
    "        colors = sns.color_palette(mode, N) + [(0,0,0)]\n",
    "    else:\n",
    "        N = np.unique(clust).max()\n",
    "        colors = sns.color_palette(mode, N) \n",
    "    return colors\n",
    "\n",
    "\n",
    "def get_axes(L, max_col=3, fig_frame=(5,4), res=100):\n",
    "    cols = L if L <= max_col else max_col\n",
    "    rows = int(L / max_col) + int(L % max_col != 0)\n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(cols * fig_frame[0], rows * fig_frame[1]), dpi=res)\n",
    "    ax =  ax.flatten()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def shuffle(X, Y=None, n=None):\n",
    "    l = np.arange(X.shape[0])\n",
    "    random.shuffle(l)\n",
    "    if Y is None:\n",
    "        return X[l[:n],:]\n",
    "    elif Y is None and n is None:\n",
    "        return X[l,:]\n",
    "    elif n is None:\n",
    "        return X[l,:], Y[l]\n",
    "    else: \n",
    "        return X[l[:n],:], Y[l[:n]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset definition and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that one wants to process needs to be load and initialized as follows\n",
    "\n",
    "`SYSX1 = np.loadtxt(my_dir/my_fileX1)`\n",
    "\n",
    "and then put in a well named dictionary\n",
    "\n",
    "`SYST = {\n",
    "    'name_X1' : SYSX1,\n",
    "    'name_X2' : SYSX2,\n",
    "        ...   : ...  ,\n",
    "}`\n",
    "\n",
    "As stated before in this workflow one need to define a _wholesystemData_ and store it accordingly\n",
    "\n",
    "`ALL = np.loadtxt(my_dir/my_wholedata)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_DIR='/home/andreag/SOFTSYSTEMS/FIBERSminimal_10mu/pca_files/rcut8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS1 = np.loadtxt(PCA_DIR+'/PCA_fiber1_c1_10mu_ev10ns_rcut8_trj0-1001-1.pca')\n",
    "SYS2 = np.loadtxt(PCA_DIR+'/PCA_fiber2_c5_10mu_ev10ns_rcut8_trj0-1001-1.pca')\n",
    "SYS3 = np.loadtxt(PCA_DIR+'/PCA_fiber3_n0_10mu_ev10ns_rcut8_trj0-1001-1.pca')\n",
    "ALL = np.loadtxt(PCA_DIR+'/wholesystem.pca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYST = {\n",
    "    'fib1' : SYS1,\n",
    "    'fib2' : SYS2,\n",
    "    'fib3' : SYS3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = ALL.shape[1]\n",
    "print(f\"Data dimensions considered: {DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK=5000\n",
    "LABEL_SIZE=18\n",
    "L=len(SYST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shffull = shuffle(ALL)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(shffull[:CHUNK,0], shffull[:CHUNK,1])\n",
    "ax.set_title('whole data visualization')\n",
    "gx = ax.get_xlim()\n",
    "gy = ax.get_ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paramters for the calculation needs to be stored as follows.\n",
    "\n",
    "The meaning of these parameters can be found in the orignal [paper](https://pubs.acs.org/doi/abs/10.1021/acs.jctc.7b00993).\n",
    "\n",
    "The `nm_frame` refers to how many components a frame of the trajectory is composed (es. fiber having 40 monomers `nm_frame : 40`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_inputs = dict(\n",
    "    # cluster\n",
    "    distance = \"minkowski\",\n",
    "    size = 2000,\n",
    "    p = 2,\n",
    "    generate_grid = True,\n",
    "    savegrid = \"grid_data\",\n",
    "    # cluster inputs\n",
    "    d = DIM,\n",
    "    fspread = 0.25,\n",
    "    ngrid = 2000,\n",
    "    qs = 1,\n",
    "    o = \"pamm\",\n",
    "    trajectory = PCA_DIR+\"/wholesystem.pca\",\n",
    "    readgrid = \"grid_data\",\n",
    "    merger = 0.01,\n",
    "    bootstrap = 73\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_cluster = [\n",
    "    (ALL, {}),\n",
    "]\n",
    "\n",
    "datasets_predict = [\n",
    "    (SYS1, {'sys' : 'fib1', 'nm_frame' : 40}),\n",
    "    (SYS2, {'sys' : 'fib2', 'nm_frame' : 40}),\n",
    "    (SYS3, {'sys' : 'fib3', 'nm_frame' : 40})\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original dataset plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=sns.color_palette('tab10', L)\n",
    "fig, ax = get_axes(L, max_col=L)\n",
    "for i,s in enumerate(SYST):\n",
    "    ax[i].scatter(SYST[s][:CHUNK,0], SYST[s][:CHUNK,1], s=10, linewidth=1, marker=\"o\", alpha=0.5)\n",
    "    ax[i].set_xlim(gx)\n",
    "    ax[i].set_ylim(gy)\n",
    "    ax[i].set_title(f\"{s}\", weight='bold',size=LABEL_SIZE)\n",
    "    ax[i].tick_params(labelsize=LABEL_SIZE,width=3,size=7)\n",
    "    \n",
    "    for side in ['bottom','right','top','left']:\n",
    "        ax[i].spines[side].set_linewidth(3)\n",
    "    \n",
    "    if i == 0:\n",
    "        ax[i].set_xlabel('PCA 1', weight='bold',size=LABEL_SIZE)\n",
    "        ax[i].set_ylabel('PCA 2', weight='bold',size=LABEL_SIZE)\n",
    "        for side in ['right','top']:\n",
    "            ax[i].spines[side].set_visible(False)          \n",
    "    else:\n",
    "        ax[i].set_xlabel('PCA 1', weight='bold',size=LABEL_SIZE)\n",
    "        ax[i].tick_params(labelleft=None)\n",
    "        for side in ['right','top']:\n",
    "            ax[i].spines[side].set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig(\"data_set_soap_pca.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAMM - Clustering part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_dataset, (dataset, algo_params) in enumerate(datasets_cluster):\n",
    "    # update parameters with dataset-specific values\n",
    "    params = default_inputs.copy()\n",
    "    params.update(algo_params)\n",
    "\n",
    "    # Clustering\n",
    "    p = Pamm(params)\n",
    "    print('\\n#-----------------------------------------------')\n",
    "    print(p.command_parser)\n",
    "    \n",
    "    print('\\nRUNNING Clustering')\n",
    "    t0 = time.time()\n",
    "    p.run()\n",
    "    t1 = time.time()\n",
    "    print('TIME= '+str(np.round(t1-t0, 2))+' s \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAMM - Prediction on data part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = PammGMM.read_clusters('pamm.pamm', \n",
    "                                grid_file='pamm.grid', \n",
    "                                bootstrap_file='pamm.bs')\n",
    "NUM_CLUST=np.unique(gmm.pk).shape[0]\n",
    "print(f\"There are {NUM_CLUST} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_output = {}\n",
    "grid_cluster = {}\n",
    "prob_output = {}\n",
    "bootstr_output = {}\n",
    "systnames = []\n",
    "for i_dataset,dataset in enumerate(datasets_predict):\n",
    "    run_syst = str(datasets_predict[i_dataset][1]['sys'])\n",
    "    # Predict\n",
    "    print('\\nRUNNING Predict '+run_syst)\n",
    "    t0 = time.time()\n",
    "    \n",
    "    x = datasets_predict[i_dataset][0]\n",
    "    x_ = gmm.predict_proba(x)\n",
    "    labels = np.argmax(x_, axis=1) #.reshape((-1, 1))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print('TIME= '+str(np.round(t1-t0, 2))+' s \\n')\n",
    "\n",
    "    # Storing data\n",
    "    cluster_output[run_syst] = labels\n",
    "    grid_cluster[run_syst] = gmm.cluster\n",
    "    prob_output[run_syst] = gmm.p\n",
    "    bootstr_output[run_syst] = gmm.bs\n",
    "    systnames.append(run_syst)\n",
    "\n",
    "    # output for initial clustering\n",
    "    np.savetxt(run_syst + \"_clusters.txt\", labels.reshape((-1, 1)))\n",
    "    \n",
    "    rates = ClusterRates(datasets_predict[i_dataset][1]['nm_frame'], 'label').calculate_matrix(labels.reshape((-1, 1)))\n",
    "    np.savetxt(run_syst + \"_rates.txt\", rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PLTmatrixrates(ax,data,s=18):\n",
    "    labels = ['0','1', '2', '3', '4', '5', '6','7','8']\n",
    "    sns.heatmap(data, annot=True, fmt=\".2f\", cbar=False, ax=ax, annot_kws={\"fontsize\":s})\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.set_xticklabels(labels, size='18', weight='bold')\n",
    "    ax.set_yticklabels(labels, size='18', weight='bold')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=make_colors(NUM_CLUST,mode='tab20')\n",
    "fig, ax = get_axes(L, max_col=L)\n",
    "for i,sys in enumerate(systnames):\n",
    "    labels = cluster_output[sys]\n",
    "    ax[i].scatter(datasets_predict[i][0][:CHUNK,0], datasets_predict[i][0][:CHUNK,1], c=np.array(colors)[labels[:CHUNK]], s=10)\n",
    "    ax[i].set_xlim(gx)\n",
    "    ax[i].set_ylim(gy)\n",
    "    ax[i].set_title(f\"{sys}\", weight='bold',size=LABEL_SIZE)\n",
    "    ax[i].tick_params(labelsize=LABEL_SIZE,width=3,size=7)\n",
    "    \n",
    "    for side in ['bottom','right','top','left']:\n",
    "        ax[i].spines[side].set_linewidth(3)\n",
    "    \n",
    "    if i == 0:\n",
    "        ax[i].set_xlabel('PCA 1', weight='bold',size=LABEL_SIZE)\n",
    "        ax[i].set_ylabel('PCA 2', weight='bold',size=LABEL_SIZE)\n",
    "        for side in ['right','top']:\n",
    "            ax[i].spines[side].set_visible(False)          \n",
    "    else:\n",
    "        ax[i].set_xlabel('PCA 1', weight='bold',size=LABEL_SIZE)\n",
    "        ax[i].tick_params(labelleft=None)\n",
    "        for side in ['right','top']:\n",
    "            ax[i].spines[side].set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig('clusters_pamm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS1rates = np.loadtxt(\"./fib1_rates.txt\")\n",
    "SYS2rates = np.loadtxt(\"./fib2_rates.txt\")\n",
    "SYS3rates = np.loadtxt(\"./fib3_rates.txt\")\n",
    "\n",
    "RATES = {\n",
    "    'fib1' : SYS1rates,\n",
    "    'fib2' : SYS2rates,\n",
    "    'fib3' : SYS3rates,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = get_axes(L, max_col=3, fig_frame=(5,4), res=100)\n",
    "for i,sys in enumerate(RATES):\n",
    "    PLTmatrixrates(ax[i], RATES[sys], s=14)\n",
    "    \n",
    "fig.tight_layout()\n",
    "# fig.savefig('micro_clusters_pamm_matrix.png')\n",
    "#Probabilità di transizione\n",
    "#Riga partenza\n",
    "#Colonna arrivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusters hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 1\n",
    "col = 1\n",
    "fig, ax = plt.subplots(row, col, figsize=(col * 5, row * 4), dpi=100)\n",
    "\n",
    "adjacency, mapping = calculate_adjacency(\n",
    "prob=prob_output['fib3'],\n",
    "clusters=grid_cluster['fib3'],\n",
    "bootstrap=bootstr_output['fib3']\n",
    ")\n",
    "z = adjancency_dendrogram(adjacency)\n",
    "_ = dendrogram(z, ax=ax, count_sort=True)['leaves']\n",
    "    \n",
    "for k in range(col):\n",
    "    ax.set_yticks([])\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    for side in ['bottom','right','top','left']:\n",
    "        ax.spines[side].set_visible(False)\n",
    "\n",
    "\n",
    "# ax.set_ylabel('PAMM DENDROGRAM', size='16')\n",
    "fig.savefig('clusters_pamm_dendrogram.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusters mearging (Macroclusters processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macrocluster syntax definition:\n",
    "\n",
    "`mapping = [\n",
    "    ('SYSX1', {MacroCl1: [microClx,...], \n",
    "               MacroCl2: [microCly,...]})\n",
    "]`\n",
    "\n",
    "where the mearging comes from the dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = [\n",
    "    ('0.12', {0: [0,1,4],\n",
    "              1: [3,4]}),\n",
    "    ('1.15', {0: [0,1,3,4],\n",
    "             1: [2]}),\n",
    "    ('2.18', {0: [0,1,3,4],\n",
    "             1: [2]}),\n",
    "    ('3.20', {0: [0,1,3,4],\n",
    "             1: [2]}),\n",
    "    ('4.24', {0: [0,1,3,4],\n",
    "             1: [2]})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_predict[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it does not matter if one put np.argmax(y__, axis=1).reshape((-1,1)) \\w or \\wout the reshape part\n",
    "macro_cluster_output = {}\n",
    "rates_macro_clusters = {}\n",
    "\n",
    "for s,macro_cl in enumerate(systnames):\n",
    "    # Macro Cluster\n",
    "    run_syst = macro_cl\n",
    "    print(\"MACRO CLUSTERS - \"+run_syst)\n",
    "    \n",
    "    y = datasets_predict[s][0]\n",
    "    y_ = gmm.predict_proba(y)\n",
    "    y__ = np.zeros((y.shape[0], len(mapping[s][1])))\n",
    "    for k, v in mapping[s][1].items():\n",
    "        y__[:, k] = y_[:,v].sum(1)\n",
    "\n",
    "    macro_cluster_output[macro_cl] = np.argmax(y__, axis=1)\n",
    "    np.savetxt(run_syst+'_macro_cluster.dat', np.argmax(y__, axis=1).reshape((-1,1)) )\n",
    "    \n",
    "    rates = ClusterRates(datasets_predict[s][1]['nm_frame'], 'label').calculate_matrix(np.argmax(y__, axis=1).reshape((-1,1)) )\n",
    "    rates_macro_clusters[macro_cl] = rates\n",
    "    np.savetxt(run_syst+'_macro_rates.dat', rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_macro_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mcolors = [\"tab:blue\", \"tab:red\", \"tab:green\"]\n",
    "\n",
    "fig, ax = get_axes(L, max_col=L)\n",
    "for i,sys in enumerate(SYST):\n",
    "    colors=Mcolors\n",
    "    labels = macro_cluster_output[sys]\n",
    "    ax[i].scatter(datasets_predict[i][0][:CHUNK,0], datasets_predict[i][0][:CHUNK,1], c=np.array(colors)[labels[:CHUNK]], s=10)\n",
    "    ax[i].set_title(f\"{sys}\", weight='bold',size=LABEL_SIZE)\n",
    "    ax[i].tick_params(labelsize=LABEL_SIZE,width=3,size=7)\n",
    "    \n",
    "    ax[i].set_xlim(gx)\n",
    "    ax[i].set_ylim(gy)\n",
    "    \n",
    "    for side in ['bottom','right','top','left']:\n",
    "        ax[i].spines[side].set_linewidth(3)\n",
    "    \n",
    "    if i == 0:\n",
    "        ax[i].set_xlabel('PCA 1', weight='bold',size=LABEL_SIZE)\n",
    "        ax[i].set_ylabel('PCA 2', weight='bold',size=LABEL_SIZE)\n",
    "        for side in ['right','top']:\n",
    "            ax[i].spines[side].set_visible(False)          \n",
    "    else:\n",
    "        ax[i].set_xlabel('PCA 1', weight='bold',size=LABEL_SIZE)\n",
    "        ax[i].tick_params(labelleft=None)\n",
    "        for side in ['right','top']:\n",
    "            ax[i].spines[side].set_visible(False)\n",
    "\n",
    "fig.savefig('macro_clusters_pamm.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS1rates = np.loadtxt(\"./0.12_macro_rates.dat\")\n",
    "SYS2rates = np.loadtxt(\"./1.15_macro_rates.dat\")\n",
    "SYS3rates = np.loadtxt(\"./2.18_macro_rates.dat\")\n",
    "SYS4rates = np.loadtxt(\"./3.20_macro_rates.dat\")\n",
    "SYS5rates = np.loadtxt(\"./4.24_macro_rates.dat\")\n",
    "RATES = {\n",
    "    '0.12' : SYS1rates,\n",
    "    '1.15' : SYS2rates,\n",
    "    '2.18' : SYS3rates,\n",
    "    '3.20' : SYS4rates,\n",
    "    '4.24' : SYS5rates,\n",
    "}\n",
    "\n",
    "fig, ax = get_axes(L, max_col=3, fig_frame=(5,4), res=100)\n",
    "for i,sys in enumerate(RATES):\n",
    "    PLTmatrixrates(ax[i], RATES[sys])\n",
    "fig.savefig('macro_clusters_pamm_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
